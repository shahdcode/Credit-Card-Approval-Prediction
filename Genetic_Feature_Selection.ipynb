{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahdcode/Credit-Card-Approval-Prediction/blob/main/Genetic_Feature_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "-q-w9tnVN-vf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "qWoSbYQgDYmZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algrotihms\n"
      ],
      "metadata": {
        "id": "KsLYObk3OET3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Particle Swarm Optimization (PSO)"
      ],
      "metadata": {
        "id": "EGCFmGBPU5Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def fitness_function(features, X, y, classifier):\n",
        "#     \"\"\"\n",
        "#     Evaluate the fitness of a particle.\n",
        "\n",
        "#     Args:\n",
        "#         features (array): Binary array representing selected features.\n",
        "#         X (ndarray): Feature matrix.\n",
        "#         y (ndarray): Target array.\n",
        "#         classifier: A machine learning model (e.g., DecisionTreeClassifier).\n",
        "\n",
        "#     Returns:\n",
        "#         float: The fitness value (lower is better for minimization tasks).\n",
        "#     \"\"\"\n",
        "#     # Select features based on the binary array\n",
        "#     selected_features = X[:, features == 1]\n",
        "\n",
        "#     # If no features are selected, return a high fitness value\n",
        "#     if selected_features.shape[1] == 0:\n",
        "#         return float('inf')\n",
        "\n",
        "#     # Perform a simple train-test split (80%-20%)\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(selected_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#     # Train the classifier\n",
        "#     classifier.fit(X_train, y_train)\n",
        "\n",
        "#     # Predict and calculate accuracy\n",
        "#     y_pred = classifier.predict(X_test)\n",
        "#     accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "#     # Return the negative accuracy as fitness (minimization task)\n",
        "#     return -accuracy\n",
        "\n",
        "\n",
        "\n",
        "def fitness_function(features, X, y, classifier):\n",
        "    \"\"\"\n",
        "    Evaluate the fitness of a particle.\n",
        "\n",
        "    Args:\n",
        "        features (array): Binary array representing selected features.\n",
        "        X (ndarray): Feature matrix.\n",
        "        y (ndarray): Target array.\n",
        "        classifier: A machine learning model (e.g., DecisionTreeClassifier).\n",
        "\n",
        "    Returns:\n",
        "        float: The fitness value (lower is better for minimization tasks).\n",
        "    \"\"\"\n",
        "    # Select features based on the binary array\n",
        "    selected_features = X.iloc[:, features == 1]\n",
        "\n",
        "    # If no features are selected, return a high fitness value\n",
        "    if selected_features.shape[1] == 0:\n",
        "        return float('inf')\n",
        "\n",
        "    # Perform a simple train-test split (80%-20%)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(selected_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the classifier\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate accuracy\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Return the negative accuracy as fitness (minimization task)\n",
        "    return -accuracy\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pX9XWjo3W1yf"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_swarm(n_particles, n_features, bounds, fitness_function, X, y, classifier):\n",
        "    \"\"\"\n",
        "    Initialize the swarm for PSO.\n",
        "\n",
        "    Args:\n",
        "        n_particles (int): Number of particles.\n",
        "        n_features (int): Number of features.\n",
        "        bounds (tuple): Bounds for the feature mask (binary: 0 or 1).\n",
        "        fitness_function (callable): The fitness function.\n",
        "        X (ndarray): Feature matrix.\n",
        "        y (ndarray): Target array.\n",
        "        classifier: A machine learning model.\n",
        "\n",
        "    Returns:\n",
        "        positions, velocities, pbest_positions, pbest_fitness, gbest_position, gbest_fitness\n",
        "    \"\"\"\n",
        "    lower_bounds, upper_bounds = bounds\n",
        "\n",
        "    # Randomly initialize positions (binary: 0 or 1) and velocities\n",
        "    positions = np.random.randint(lower_bounds, upper_bounds + 1, size=(n_particles, n_features))\n",
        "    velocities = np.random.uniform(-1, 1, (n_particles, n_features))\n",
        "\n",
        "    # Evaluate initial fitness\n",
        "    fitness = np.array([fitness_function(positions[i], X, y, classifier) for i in range(n_particles)])\n",
        "\n",
        "    # Set personal bests (pbest)\n",
        "    pbest_positions = positions.copy()\n",
        "    pbest_fitness = fitness.copy()\n",
        "\n",
        "    # Set global best (gbest)\n",
        "    gbest_index = np.argmin(pbest_fitness)\n",
        "    gbest_position = pbest_positions[gbest_index]\n",
        "    gbest_fitness = pbest_fitness[gbest_index]\n",
        "\n",
        "    return positions, velocities, pbest_positions, pbest_fitness, gbest_position, gbest_fitness\n"
      ],
      "metadata": {
        "id": "5FSJe6s-W-Aw"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def return_best_solution(gbest_position, gbest_fitness, feature_names):\n",
        "#     \"\"\"\n",
        "#     Return the best solution found by the swarm.\n",
        "\n",
        "#     Args:\n",
        "#         gbest_position (array): The best feature mask.\n",
        "#         gbest_fitness (float): The best fitness value.\n",
        "#         feature_names (list): List of feature names.\n",
        "\n",
        "#     Returns:\n",
        "#         dict: A dictionary containing selected features and their fitness.\n",
        "#     \"\"\"\n",
        "#     selected_features = [feature_names[i] for i in range(len(gbest_position)) if gbest_position[i] == 1]\n",
        "#     return {\n",
        "#         \"Selected Features\": selected_features,\n",
        "#         \"Best Fitness\": -gbest_fitness  # Accuracy is the positive value of fitness\n",
        "#     }\n",
        "\n",
        "def return_best_solution(gbest_position, gbest_fitness, feature_names):\n",
        "    \"\"\"\n",
        "    Return the best solution found by the swarm.\n",
        "\n",
        "    Args:\n",
        "        gbest_position (array): The best feature mask.\n",
        "        gbest_fitness (float): The best fitness value.\n",
        "        feature_names (list): List of feature names.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing selected features and their fitness.\n",
        "    \"\"\"\n",
        "    selected_features = [feature_names[i] for i in range(len(feature_names)) if gbest_position[i] == 1]\n",
        "    return {\n",
        "        \"Selected Features\": selected_features,\n",
        "        \"Best Fitness\": -gbest_fitness  # Accuracy is the positive value of fitness\n",
        "    }\n"
      ],
      "metadata": {
        "id": "kO45L-wnW_mr"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shahd\n",
        "def update_swarm(positions, velocities, fitness_function, pbest_positions, pbest_fitness, gbest_position, w, c1, c2, bounds, X, y, classifier):\n",
        "    lower_bounds, upper_bounds = bounds\n",
        "    n_particles, dimensions = positions.shape\n",
        "\n",
        "    # Temporarily cast positions to float64 for update step\n",
        "    positions = positions.astype(np.float64)\n",
        "\n",
        "    for i in range(n_particles):\n",
        "        # Update velocity\n",
        "        inertia = w * velocities[i]\n",
        "        cognitive = c1 * np.random.random() * (pbest_positions[i] - positions[i])\n",
        "        social = c2 * np.random.random() * (gbest_position - positions[i])\n",
        "        velocities[i] = inertia + cognitive + social\n",
        "\n",
        "        # Update position\n",
        "        positions[i] += velocities[i]\n",
        "\n",
        "        # Ensure positions stay within bounds (binary: 0 or 1)\n",
        "        positions[i] = np.clip(positions[i], lower_bounds, upper_bounds)\n",
        "\n",
        "    # After update, cast positions back to int64 for binary (0, 1)\n",
        "    positions = np.round(positions).astype(np.int64)\n",
        "\n",
        "    # Evaluate fitness\n",
        "    fitness = np.array([fitness_function(positions[i], X, y, classifier) for i in range(n_particles)])\n",
        "\n",
        "    # Update pbest\n",
        "    for i in range(n_particles):\n",
        "        if fitness[i] < pbest_fitness[i]:\n",
        "            pbest_fitness[i] = fitness[i]\n",
        "            pbest_positions[i] = positions[i]\n",
        "\n",
        "    # Update gbest\n",
        "    gbest_index = np.argmin(fitness)\n",
        "    if fitness[gbest_index] < np.min(pbest_fitness):\n",
        "        gbest_position = positions[gbest_index]\n",
        "\n",
        "    return positions, velocities, pbest_positions, pbest_fitness, gbest_position\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AOLz7TzpI5vg"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Genetic Algorithm Implementation"
      ],
      "metadata": {
        "id": "Giuxc_6sZNtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1 - Shahd\n",
        "def encode_solution_space(num_features):\n",
        "    \"\"\"Creates binary encoding for feature selection.\"\"\"\n",
        "    return np.random.choice([0, 1], size=num_features)\n"
      ],
      "metadata": {
        "id": "iGAZQYP0Go55"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2 - Habiba\n",
        "def set_algorithm_parameters():\n",
        "    \"\"\"Set the parameters for the Genetic Algorithm.\"\"\"\n",
        "    return {\n",
        "        \"pop_size\": 100,\n",
        "        \"num_generations\": 150,\n",
        "        \"crossover_rate\": 0.9,\n",
        "        \"mutation_rate\": 0.02\n",
        "    }"
      ],
      "metadata": {
        "id": "_EglotfOZVFJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3 - Shahd\n",
        "def create_initial_population(pop_size, num_features):\n",
        "    \"\"\"Generates the initial population of chromosomes.\"\"\"\n",
        "    return [encode_solution_space(num_features) for _ in range(pop_size)]"
      ],
      "metadata": {
        "id": "KNJ9TMGfGwob"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4 - Shahd\n",
        "\n",
        "def measure_fitness(population, X_train, y_train, X_val, y_val, dynamic_k):\n",
        "    \"\"\"Evaluates the fitness of each chromosome with a dynamic k value.\"\"\"\n",
        "    fitness_scores = []\n",
        "    for chromosome in population:\n",
        "        selected_features = [i for i, bit in enumerate(chromosome) if bit == 1]\n",
        "        if not selected_features:\n",
        "            fitness_scores.append(0)\n",
        "            continue\n",
        "        X_train_selected = X_train.iloc[:, selected_features]\n",
        "        X_val_selected = X_val.iloc[:, selected_features]\n",
        "\n",
        "        # Train the model with the dynamic k value\n",
        "        model = KNeighborsClassifier(n_neighbors=dynamic_k)\n",
        "        model.fit(X_train_selected, y_train)\n",
        "        predictions = model.predict(X_val_selected)\n",
        "        fitness_scores.append(accuracy_score(y_val, predictions))\n",
        "    return fitness_scores\n",
        "\n",
        "\n",
        "# def measure_fitness(population, X_train, y_train, X_val, y_val, best_k=5):\n",
        "#     \"\"\"Evaluates the fitness of each chromosome (feature selection) in the population.\"\"\"\n",
        "#     fitness_scores = []\n",
        "#     for chromosome in population:\n",
        "#         selected_features = [i for i, bit in enumerate(chromosome) if bit == 1]\n",
        "#         if not selected_features:\n",
        "#             fitness_scores.append(0)\n",
        "#             continue\n",
        "#         X_train_selected = X_train.iloc[:, selected_features]\n",
        "#         X_val_selected = X_val.iloc[:, selected_features]\n",
        "\n",
        "#         # Train the model with the default value for k (e.g., k=5)\n",
        "#         model = KNeighborsClassifier(n_neighbors=best_k)\n",
        "#         model.fit(X_train_selected, y_train)\n",
        "#         predictions = model.predict(X_val_selected)\n",
        "#         fitness_scores.append(accuracy_score(y_val, predictions))\n",
        "#     return fitness_scores\n",
        ""
      ],
      "metadata": {
        "id": "FAWSwijVG1m8"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5 - Habiba\n",
        "# def select_parents(population, fitness_values):\n",
        "#     \"\"\"Select parents using Tournament Selection.\"\"\"\n",
        "#     parents = []\n",
        "#     for _ in range(len(population)):\n",
        "#         # Tournament selection: Randomly pick 3 and select the best\n",
        "#         candidates_idx = np.random.choice(len(population), 3, replace=False)\n",
        "#         best_candidate = max(candidates_idx, key=lambda idx: fitness_values[idx])\n",
        "#         parents.append(population[best_candidate])\n",
        "#     return np.array(parents)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def select_parents(population, fitness_values):\n",
        "    \"\"\"Select parents using Roulette Wheel Selection.\"\"\"\n",
        "    total_fitness = sum(fitness_values)\n",
        "    selection_probs = [f / total_fitness for f in fitness_values]\n",
        "    parents = np.random.choice(population, size=len(population), p=selection_probs)\n",
        "    return np.array(parents)\n"
      ],
      "metadata": {
        "id": "a5zT8I3ab95R"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6 - Habiba\n",
        "def crossover(parents, crossover_rate):\n",
        "    \"\"\"Apply single-point crossover.\"\"\"\n",
        "    offspring = []\n",
        "    for i in range(0, len(parents), 2):\n",
        "        parent1, parent2 = parents[i], parents[(i + 1) % len(parents)]\n",
        "        if np.random.rand() < crossover_rate:\n",
        "            point = np.random.randint(1, len(parent1))\n",
        "            child1 = np.concatenate([parent1[:point], parent2[point:]])\n",
        "            child2 = np.concatenate([parent2[:point], parent1[point:]])\n",
        "            offspring.extend([child1, child2])\n",
        "        else:\n",
        "            offspring.extend([parent1, parent2])\n",
        "    return np.array(offspring)\n"
      ],
      "metadata": {
        "id": "vPYPh9wob-eq"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 7 - Habiba\n",
        "def populate_next_generation(offspring, fitness_values):\n",
        "    \"\"\"Replace population with offspring and apply elitism.\"\"\"\n",
        "    elite_idx = np.argmax(fitness_values)\n",
        "    next_generation = offspring\n",
        "    next_generation[0] = offspring[elite_idx]  # Ensure elite survives\n",
        "    return next_generation"
      ],
      "metadata": {
        "id": "psBjdg6fcF4h"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 8 - Habiba\n",
        "def mutate(offspring, mutation_rate):\n",
        "    \"\"\"Apply bit-flip mutation.\"\"\"\n",
        "    for i in range(len(offspring)):\n",
        "        for j in range(len(offspring[i])):\n",
        "            if np.random.rand() < mutation_rate:\n",
        "                offspring[i][j] = 1 - offspring[i][j]  # Flip bit\n",
        "    return offspring\n"
      ],
      "metadata": {
        "id": "hq0RNObNcFQa"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 9 - Shahd\n",
        "# def check_stopping_condition(generation, max_generations, fitness_scores, threshold, no_change_limit, previous_scores):\n",
        "#     \"\"\"Checks if the algorithm should stop based on fitness, generations, or stagnation.\"\"\"\n",
        "#     if generation >= max_generations or max(fitness_scores) >= threshold:\n",
        "#         return True\n",
        "#     if len(previous_scores) >= no_change_limit and all(score == previous_scores[0] for score in previous_scores):\n",
        "#         return True\n",
        "#     return False\n",
        "\n",
        "\n",
        "def check_stopping_condition(generation, max_generations, fitness_scores, threshold, no_change_limit, previous_scores):\n",
        "    \"\"\"Checks if the algorithm should stop based on fitness, generations, or stagnation.\"\"\"\n",
        "    if generation >= max_generations or max(fitness_scores) >= threshold:\n",
        "        return True\n",
        "    if len(previous_scores) >= no_change_limit and all(score == previous_scores[0] for score in previous_scores):\n",
        "        return True\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "KxcB3rUmG5PH"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def genetic_algorithm(X_train, y_train, X_val, y_val, num_features):\n",
        "    \"\"\"Runs the genetic algorithm for feature selection with a dynamic k.\"\"\"\n",
        "    params = set_algorithm_parameters()\n",
        "    params['no_change_limit'] = 10  # Define stagnation limit\n",
        "    population = create_initial_population(params['pop_size'], num_features)\n",
        "    previous_scores = []\n",
        "\n",
        "    for generation in range(params['num_generations']):\n",
        "        # Dynamically compute the best k for the current generation\n",
        "        dynamic_k, _ = find_optimal_k(X_train, y_train)\n",
        "\n",
        "        # Evaluate fitness with the dynamic k value\n",
        "        fitness_scores = measure_fitness(population, X_train, y_train, X_val, y_val, dynamic_k)\n",
        "\n",
        "        if check_stopping_condition(generation, params['num_generations'], fitness_scores, 0.95, params['no_change_limit'], previous_scores):\n",
        "            break\n",
        "\n",
        "        previous_scores.append(max(fitness_scores))\n",
        "        if len(previous_scores) > params['no_change_limit']:\n",
        "            previous_scores.pop(0)\n",
        "\n",
        "        parents = select_parents(population, fitness_scores)\n",
        "        offspring = crossover(parents, params['crossover_rate'])\n",
        "        offspring = mutate(offspring, params['mutation_rate'])\n",
        "        population = populate_next_generation(offspring, fitness_scores)\n",
        "\n",
        "    best_solution = population[np.argmax(fitness_scores)]\n",
        "    return best_solution, max(fitness_scores)  # Return best solution and fitness score\n",
        "\n"
      ],
      "metadata": {
        "id": "FGKav0l0Huy1"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knn"
      ],
      "metadata": {
        "id": "GrVJKEH8NzO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_optimal_k(X_train, y_train):\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "    param_grid = {'n_neighbors': list(range(1, 31))}\n",
        "    grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search.best_params_['n_neighbors'], grid_search.best_score_\n"
      ],
      "metadata": {
        "id": "XGFx9norODWB"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_knn_and_display_accuracy(X_train, y_train, X_val, y_val, X_test, y_test, best_k):\n",
        "    # Initialize the KNN model with the optimal k\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
        "\n",
        "    # Train the model on the training set\n",
        "    knn_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_val_pred = knn_model.predict(X_val)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_test_pred = knn_model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy on the validation set\n",
        "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "    # Calculate accuracy on the test set\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    # Display the accuracies\n",
        "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "IrBZQRhjhTl4"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def separate_features_targets(train_df, val_df, test_df):\n",
        "    \"\"\"\n",
        "    Function to separate features and target from three datasets (train, validation, and test).\n",
        "\n",
        "    Parameters:\n",
        "    - train_df: DataFrame for training data\n",
        "    - val_df: DataFrame for validation data\n",
        "    - test_df: DataFrame for test data\n",
        "\n",
        "    Returns:\n",
        "    - X_train, X_val, X_test: Features for train, validation, and test sets\n",
        "    - y_train, y_val, y_test: Target labels for train, validation, and test sets\n",
        "    \"\"\"\n",
        "    # Separate features and target for training set\n",
        "    X_train = train_df.drop(columns=['status_mapped'])\n",
        "    y_train = train_df['status_mapped']\n",
        "\n",
        "    # Separate features and target for validation set\n",
        "    X_val = val_df.drop(columns=['status_mapped'])\n",
        "    y_val = val_df['status_mapped']\n",
        "\n",
        "    # Separate features and target for test set\n",
        "    X_test = test_df.drop(columns=['status_mapped'])\n",
        "    y_test = test_df['status_mapped']\n",
        "\n",
        "    # Return all the variables\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n"
      ],
      "metadata": {
        "id": "MOqZKbNa64GT"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_scaled_df=pd.read_csv('/content/drive/MyDrive/Ai project/train_scaled.csv')\n",
        "val_scaled=pd.read_csv('/content/drive/MyDrive/Ai project/validation_scaled.csv')\n",
        "test_scaled=pd.read_csv('/content/drive/MyDrive/Ai project/test_scaled.csv')\n",
        "\n",
        "# Load the data\n",
        "\n",
        "# Drop the 'ID' column\n",
        "train_scaled_df = train_scaled_df.drop(columns=['ID'])\n",
        "val_scaled = val_scaled.drop(columns=['ID'])\n",
        "test_scaled = test_scaled.drop(columns=['ID'])"
      ],
      "metadata": {
        "id": "dm4vJKAlXygU"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the column names of the scaled datasets\n",
        "print(\"Train DataFrame Columns:\", train_scaled_df.columns)\n",
        "print(\"Validation DataFrame Columns:\", val_scaled.columns)\n",
        "print(\"Test DataFrame Columns:\", test_scaled.columns)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPZYFrkBbkau",
        "outputId": "c66b97ad-3083-4964-e5fd-0deaf86a2063"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame Columns: Index(['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n",
            "       'AMT_INCOME_TOTAL', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
            "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'FLAG_MOBIL',\n",
            "       'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE',\n",
            "       'CNT_FAM_MEMBERS', 'AGE_YEARS', 'YEARS_EMPLOYED', 'status_mapped'],\n",
            "      dtype='object')\n",
            "Validation DataFrame Columns: Index(['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n",
            "       'AMT_INCOME_TOTAL', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
            "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'FLAG_MOBIL',\n",
            "       'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE',\n",
            "       'CNT_FAM_MEMBERS', 'AGE_YEARS', 'YEARS_EMPLOYED', 'status_mapped'],\n",
            "      dtype='object')\n",
            "Test DataFrame Columns: Index(['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n",
            "       'AMT_INCOME_TOTAL', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
            "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'FLAG_MOBIL',\n",
            "       'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE',\n",
            "       'CNT_FAM_MEMBERS', 'AGE_YEARS', 'YEARS_EMPLOYED', 'status_mapped'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the split_data function\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = separate_features_targets(train_scaled_df, val_scaled, test_scaled)\n",
        "\n",
        "# Run PSO for feature selection (same as previous code)\n",
        "classifier = KNeighborsClassifier()\n",
        "n_particles = 30\n",
        "n_features = X_train.shape[1]\n",
        "bounds = (0, 1)  # Binary feature selection\n",
        "\n",
        "positions, velocities, pbest_positions, pbest_fitness, gbest_position, gbest_fitness = initialize_swarm(\n",
        "    n_particles, n_features, bounds, fitness_function, X_train, y_train, classifier\n",
        ")\n",
        "\n",
        "# Track the PSO process using tqdm\n",
        "for _ in tqdm(range(100), desc=\"PSO Iterations\"):  # Max iterations\n",
        "    positions, velocities, pbest_positions, pbest_fitness, gbest_position = update_swarm(\n",
        "        positions, velocities, fitness_function, pbest_positions, pbest_fitness, gbest_position,\n",
        "        w=0.5, c1=1.5, c2=1.5, bounds=bounds, X=X_train, y=y_train, classifier=classifier\n",
        "    )\n",
        "\n",
        "pso_result = return_best_solution(gbest_position, gbest_fitness, X_train.columns)\n",
        "selected_features_pso = pso_result[\"Selected Features\"]\n",
        "print(\"PSO Best Features:\", selected_features_pso)\n",
        "print(\"PSO Best Fitness (Accuracy):\", pso_result[\"Best Fitness\"])\n",
        "\n",
        "# Filter training, validation, and test sets by PSO-selected features\n",
        "X_train_selected_pso = X_train[selected_features_pso]\n",
        "X_val_selected_pso = X_val[selected_features_pso]\n",
        "X_test_selected_pso = X_test[selected_features_pso]\n",
        "\n",
        "# Train and evaluate KNN with PSO-selected features\n",
        "best_k, best_score = find_optimal_k(X_train_selected_pso, y_train)\n",
        "print(f\"Optimal k (PSO): {best_k} with cross-validation accuracy: {best_score}\")\n",
        "\n",
        "knn_model_pso = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn_model_pso.fit(X_train_selected_pso, y_train)\n",
        "y_pred_pso = knn_model_pso.predict(X_val_selected_pso)\n",
        "accuracy_pso = accuracy_score(y_val, y_pred_pso)\n",
        "print(f\"Accuracy of KNN with PSO-selected features and k={best_k}: {accuracy_pso}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn5fvsukH2Rj",
        "outputId": "4e4cc81c-2ddf-46f5-b05b-5b32c46c6bf6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PSO Iterations: 100%|██████████| 100/100 [27:01<00:00, 16.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSO Best Features: ['ID', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_FAMILY_STATUS', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'AGE_YEARS']\n",
            "PSO Best Fitness (Accuracy): 0.9500554938956715\n",
            "Optimal k (PSO): 21 with cross-validation accuracy: 0.9498712403624945\n",
            "Accuracy of KNN with PSO-selected features and k=21: 0.9498549523414836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and targets\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = separate_features_targets(train_scaled_df, val_scaled, test_scaled)\n",
        "\n",
        "# Run Genetic Algorithm for feature selection (without passing best_k)\n",
        "ga_best_solution, ga_best_fitness = genetic_algorithm(X_train, y_train, X_val, y_val, num_features=X_train.shape[1])\n",
        "\n",
        "# Print the best solution from the genetic algorithm\n",
        "print(\"GA Best Solution:\", ga_best_solution)\n",
        "\n",
        "# Get the names of the selected features (those with a 1 in ga_best_solution)\n",
        "ga_selected_columns = [X_train.columns[i] for i, bit in enumerate(ga_best_solution) if bit == 1]\n",
        "\n",
        "# Print the selected columns\n",
        "print(\"GA Selected Columns:\", ga_selected_columns)\n",
        "\n",
        "# Filter the training, validation, and test sets by GA-selected features using column names\n",
        "X_train_selected_ga = X_train[ga_selected_columns]\n",
        "X_val_selected_ga = X_val[ga_selected_columns]\n",
        "X_test_selected_ga = X_test[ga_selected_columns]\n",
        "\n",
        "# Convert to numpy arrays if needed\n",
        "X_train_selected_ga = X_train_selected_ga.values\n",
        "X_val_selected_ga = X_val_selected_ga.values\n",
        "X_test_selected_ga = X_test_selected_ga.values\n",
        "\n",
        "# Print the GA selected features\n",
        "print(\"GA Selected Features:\", ga_selected_columns)\n",
        "print(\"GA Best Fitness (Accuracy):\", ga_best_fitness)\n",
        "\n",
        "# Find optimal k for KNN after feature selection\n",
        "best_k, best_score = find_optimal_k(X_train_selected_ga, y_train)\n",
        "print(f\"Optimal k (GA): {best_k} with cross-validation accuracy: {best_score}\")\n",
        "\n",
        "# Train the KNN model and display the accuracy\n",
        "train_knn_and_display_accuracy(X_train_selected_ga, y_train, X_val_selected_ga, y_val, X_test_selected_ga, y_test, best_k)"
      ],
      "metadata": {
        "id": "jxxGykCM7Ij_",
        "outputId": "1aaebeb1-af4f-421e-c7f1-38b6d2751b78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GA Best Solution: [1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1]\n",
            "GA Selected Columns: ['CODE_GENDER', 'FLAG_OWN_CAR', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS', 'YEARS_EMPLOYED']\n",
            "GA Selected Features: ['CODE_GENDER', 'FLAG_OWN_CAR', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS', 'YEARS_EMPLOYED']\n",
            "GA Best Fitness (Accuracy): 0.950269374222959\n",
            "Optimal k (GA): 27 with cross-validation accuracy: 0.9498712403624945\n",
            "Validation Accuracy: 0.9498549523414836\n",
            "Test Accuracy: 0.9498653407913819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACr8k6skjO6-",
        "outputId": "52cba898-f1ba-4eb4-c65a-8c88f7978ff8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "W14pZj7suCWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Function to find the optimal number of estimators for Random Forest\n",
        "def find_optimal_estimators(X_train, y_train):\n",
        "    param_grid = {'n_estimators': list(range(10, 201, 10))}\n",
        "    grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search.best_params_['n_estimators'], grid_search.best_score_\n",
        "\n",
        "# Function to split the data\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = separate_features_targets(train_scaled_df,val_scaled,test_scaled)\n",
        "\n",
        "# PSO for feature selection (placeholder functions for initialization and update)\n",
        "classifier = RandomForestClassifier(random_state=42)\n",
        "n_particles = 30\n",
        "n_features = X_train.shape[1]\n",
        "bounds = (0, 1)  # Binary feature selection\n",
        "\n",
        "positions, velocities, pbest_positions, pbest_fitness, gbest_position, gbest_fitness = initialize_swarm(\n",
        "    n_particles, n_features, bounds, fitness_function, X_train, y_train, classifier\n",
        ")\n",
        "\n",
        "# Track the PSO process using tqdm\n",
        "for _ in tqdm(range(100), desc=\"PSO Iterations\"):\n",
        "    positions, velocities, pbest_positions, pbest_fitness, gbest_position = update_swarm(\n",
        "        positions, velocities, fitness_function, pbest_positions, pbest_fitness, gbest_position,\n",
        "        w=0.5, c1=1.5, c2=1.5, bounds=bounds, X=X_train, y=y_train, classifier=classifier\n",
        "    )\n",
        "\n",
        "pso_result = return_best_solution(gbest_position, gbest_fitness, df.drop(columns=['status_mapped']).columns)\n",
        "selected_features_pso = pso_result[\"Selected Features\"]\n",
        "print(\"PSO Best Features:\", selected_features_pso)\n",
        "print(\"PSO Best Fitness (Accuracy):\", pso_result[\"Best Fitness\"])\n",
        "\n",
        "# Filter training, validation, and test sets by PSO-selected features\n",
        "X_train_selected_pso = X_train[:, gbest_position.astype(bool)]\n",
        "X_val_selected_pso = X_val[:, gbest_position.astype(bool)]\n",
        "X_test_selected_pso = X_test[:, gbest_position.astype(bool)]\n",
        "\n",
        "# Train and evaluate Random Forest with PSO-selected features\n",
        "best_estimators, best_score = find_optimal_estimators(X_train_selected_pso, y_train)\n",
        "print(f\"Optimal number of estimators (PSO): {best_estimators} with cross-validation accuracy: {best_score}\")\n",
        "\n",
        "rf_model_pso = RandomForestClassifier(n_estimators=best_estimators, random_state=42)\n",
        "rf_model_pso.fit(X_train_selected_pso, y_train)\n",
        "y_pred_pso = rf_model_pso.predict(X_val_selected_pso)\n",
        "accuracy_pso = accuracy_score(y_val, y_pred_pso)\n",
        "print(f\"Accuracy of Random Forest with PSO-selected features: {accuracy_pso}\")\n",
        "\n",
        "# Genetic Algorithm (GA) for feature selection\n",
        "# Placeholder genetic_algorithm function\n",
        "# ga_best_solution, ga_best_fitness = genetic_algorithm(X_train, y_train, X_val, y_val, num_features=X_train.shape[1])\n",
        "# ga_selected_features = [df.drop(columns=['status_mapped']).columns[i] for i, bit in enumerate(ga_best_solution) if bit == 1]\n",
        "# print(\"GA Best Features:\", ga_selected_features)\n",
        "# print(\"GA Best Fitness (Accuracy):\", ga_best_fitness)\n",
        "\n",
        "# # Filter training, validation, and test sets by GA-selected features\n",
        "# X_train_selected_ga = X_train[:, ga_best_solution.astype(bool)]\n",
        "# X_val_selected_ga = X_val[:, ga_best_solution.astype(bool)]\n",
        "# X_test_selected_ga = X_test[:, ga_best_solution.astype(bool)]\n",
        "\n",
        "# # Train and evaluate Random Forest with GA-selected features\n",
        "# best_estimators, best_score = find_optimal_estimators(X_train_selected_ga, y_train)\n",
        "# print(f\"Optimal number of estimators (GA): {best_estimators} with cross-validation accuracy: {best_score}\")\n",
        "\n",
        "# rf_model_ga = RandomForestClassifier(n_estimators=best_estimators, random_state=42)\n",
        "# rf_model_ga.fit(X_train_selected_ga, y_train)\n",
        "# y_pred_ga = rf_model_ga.predict(X_val_selected_ga)\n",
        "# accuracy_ga = accuracy_score(y_val, y_pred_ga)\n",
        "# print(f\"Accuracy of Random Forest with GA-selected features: {accuracy_ga}\")\n",
        "\n",
        "# # Save the datasets as CSV\n",
        "# train_df = pd.concat([pd.DataFrame(X_train), pd.Series(y_train, name='status_mapped')], axis=1)\n",
        "# val_df = pd.concat([pd.DataFrame(X_val), pd.Series(y_val, name='status_mapped')], axis=1)\n",
        "# test_df = pd.concat([pd.DataFrame(X_test), pd.Series(y_test, name='status_mapped')], axis=1)\n",
        "\n",
        "# train_df.to_csv('/content/drive/MyDrive/Ai project/train_rf.csv', index=False)\n",
        "# val_df.to_csv('/content/drive/MyDrive/Ai project/validation_rf.csv', index=False)\n",
        "# test_df.to_csv('/content/drive/MyDrive/Ai project/test_rf.csv', index=False)\n",
        "\n",
        "# print(\"Datasets saved successfully:\")\n",
        "# print(f\"Train set: {train_df.shape}\")\n",
        "# print(f\"Validation set: {val_df.shape}\")\n",
        "# print(f\"Test set: {test_df.shape}\")\n"
      ],
      "metadata": {
        "id": "xzx7WBKxuCgJ",
        "outputId": "0bfc98e7-d005-4e5b-ef5e-b0f034a0a30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PSO Iterations: 100%|██████████| 100/100 [40:03<00:00, 24.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSO Best Features: ['FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'CNT_FAM_MEMBERS', 'AGE_YEARS']\n",
            "PSO Best Fitness (Accuracy): 0.9489456159822419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidIndexError",
          "evalue": "(slice(None, None, None), array([False, False,  True,  True,  True, False, False, False, False,\n       False, False, False, False,  True,  True, False, False, False]))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), array([False, False,  True,  True,  True, False, False, False, False,\n       False, False, False, False,  True,  True, False, False, False]))' is an invalid key",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-c0a5437e9195>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Filter training, validation, and test sets by PSO-selected features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mX_train_selected_pso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbest_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mX_val_selected_pso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbest_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mX_test_selected_pso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbest_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3815\u001b[0m             \u001b[0;31m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3816\u001b[0m             \u001b[0;31m#  the TypeError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3817\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3818\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   6057\u001b[0m             \u001b[0;31m# if key is not a scalar, directly raise an error (the code below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6058\u001b[0m             \u001b[0;31m# would convert to numpy arrays and raise later any way) - GH29926\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6059\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6061\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), array([False, False,  True,  True,  True, False, False, False, False,\n       False, False, False, False,  True,  True, False, False, False]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Function to find the optimal C and kernel for SVM\n",
        "def find_optimal_svm(X_train, y_train):\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf', 'poly'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    }\n",
        "    grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search.best_params_, grid_search.best_score_\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Ai project/Feature_eng_updated.csv')\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns=['status_mapped']).values  # Features as numpy array\n",
        "y = df['status_mapped'].values                # Target (label)\n",
        "\n",
        "# Split data\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = separate_features_targets(train_scaled_df,val_scaled,test_scaled)\n",
        "\n",
        "# Run PSO for feature selection\n",
        "classifier = SVC()\n",
        "n_particles = 30\n",
        "n_features = X_train.shape[1]\n",
        "bounds = (0, 1)  # Binary feature selection\n",
        "\n",
        "positions, velocities, pbest_positions, pbest_fitness, gbest_position, gbest_fitness = initialize_swarm(\n",
        "    n_particles, n_features, bounds, fitness_function, X_train, y_train, classifier\n",
        ")\n",
        "\n",
        "# Track the PSO process using tqdm\n",
        "for _ in tqdm(range(100), desc=\"PSO Iterations\"):  # Max iterations\n",
        "    positions, velocities, pbest_positions, pbest_fitness, gbest_position = update_swarm(\n",
        "        positions, velocities, fitness_function, pbest_positions, pbest_fitness, gbest_position,\n",
        "        w=0.5, c1=1.5, c2=1.5, bounds=bounds, X=X_train, y=y_train, classifier=classifier\n",
        "    )\n",
        "\n",
        "pso_result = return_best_solution(gbest_position, gbest_fitness, df.drop(columns=['status_mapped']).columns)\n",
        "selected_features_pso = pso_result[\"Selected Features\"]\n",
        "print(\"PSO Best Features:\", selected_features_pso)\n",
        "print(\"PSO Best Fitness (Accuracy):\", pso_result[\"Best Fitness\"])\n",
        "\n",
        "# Filter training, validation, and test sets by PSO-selected features\n",
        "X_train_selected_pso = X_train[:, gbest_position.astype(bool)]\n",
        "X_val_selected_pso = X_val[:, gbest_position.astype(bool)]\n",
        "X_test_selected_pso = X_test[:, gbest_position.astype(bool)]\n",
        "\n",
        "# Find optimal parameters for SVM after PSO feature selection\n",
        "best_params, best_score = find_optimal_svm(X_train_selected_pso, y_train)\n",
        "print(f\"Optimal parameters (PSO): {best_params} with cross-validation accuracy: {best_score}\")\n",
        "\n",
        "# Train and evaluate SVM with PSO-selected features\n",
        "svm_model_pso = SVC(**best_params)\n",
        "svm_model_pso.fit(X_train_selected_pso, y_train)\n",
        "y_pred_pso = svm_model_pso.predict(X_val_selected_pso)\n",
        "accuracy_pso = accuracy_score(y_val, y_pred_pso)\n",
        "print(f\"Accuracy of SVM with PSO-selected features: {accuracy_pso}\")\n",
        "\n",
        "# # Run Genetic Algorithm for feature selection (without passing best_params)\n",
        "# ga_best_solution, ga_best_fitness = genetic_algorithm(X_train, y_train, X_val, y_val, num_features=X_train.shape[1])\n",
        "# ga_selected_features = [df.drop(columns=['status_mapped']).columns[i] for i, bit in enumerate(ga_best_solution) if bit == 1]\n",
        "# print(\"GA Best Features:\", ga_selected_features)\n",
        "# print(\"GA Best Fitness (Accuracy):\", ga_best_fitness)\n",
        "\n",
        "# # Filter training, validation, and test sets by GA-selected features\n",
        "# X_train_selected_ga = X_train[:, ga_best_solution.astype(bool)]\n",
        "# X_val_selected_ga = X_val[:, ga_best_solution.astype(bool)]\n",
        "# X_test_selected_ga = X_test[:, ga_best_solution.astype(bool)]\n",
        "\n",
        "# # Find optimal parameters for SVM after GA feature selection\n",
        "# best_params, best_score = find_optimal_svm(X_train_selected_ga, y_train)\n",
        "# print(f\"Optimal parameters (GA): {best_params} with cross-validation accuracy: {best_score}\")\n",
        "\n",
        "# # Train and evaluate SVM with GA-selected features\n",
        "# svm_model_ga = SVC(**best_params)\n",
        "# svm_model_ga.fit(X_train_selected_ga, y_train)\n",
        "# y_pred_ga = svm_model_ga.predict(X_val_selected_ga)\n",
        "# accuracy_ga = accuracy_score(y_val, y_pred_ga)\n",
        "# print(f\"Accuracy of SVM with GA-selected features: {accuracy_ga}\")\n",
        "\n",
        "# # Save the splits as CSV files (if needed, combine X and y for each split)\n",
        "# train_df = pd.concat([X_train, y_train], axis=1)\n",
        "# val_df = pd.concat([X_val, y_val], axis=1)\n",
        "# test_df = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "# train_df.to_csv('/content/drive/MyDrive/Ai project/train_svm.csv', index=False)\n",
        "# val_df.to_csv('/content/drive/MyDrive/Ai project/validation_svm.csv', index=False)\n",
        "# test_df.to_csv('/content/drive/MyDrive/Ai project/test_svm.csv', index=False)\n",
        "\n",
        "# print(\"Datasets saved successfully:\")\n",
        "# print(f\"Train set: {train_df.shape}\")\n",
        "# print(f\"Validation set: {val_df.shape}\")\n",
        "# print(f\"Test set: {test_df.shape}\")\n"
      ],
      "metadata": {
        "id": "RxRt8zgp6NCW",
        "outputId": "a08d77e3-e5d4-4f0c-e54b-cd134b272eb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PSO Iterations: 100%|██████████| 100/100 [1:43:54<00:00, 62.35s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PSO Best Features: ['CODE_GENDER', 'FLAG_OWN_CAR', 'AGE_YEARS', 'YEARS_EMPLOYED']\n",
            "PSO Best Fitness (Accuracy): 0.948723640399556\n"
          ]
        }
      ]
    }
  ]
}