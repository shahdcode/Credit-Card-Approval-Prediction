{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsrn3yYvcTUY90PfWlSdNm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahdcode/Credit-Card-Approval-Prediction/blob/main/Genetic_Feature_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Particle Swarm Optimization (PSO)"
      ],
      "metadata": {
        "id": "EGCFmGBPU5Xk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qWoSbYQgDYmZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness_function(features, X, y, classifier):\n",
        "    \"\"\"\n",
        "    Evaluate the fitness of a particle.\n",
        "\n",
        "    Args:\n",
        "        features (array): Binary array representing selected features.\n",
        "        X (ndarray): Feature matrix.\n",
        "        y (ndarray): Target array.\n",
        "        classifier: A machine learning model (e.g., DecisionTreeClassifier).\n",
        "\n",
        "    Returns:\n",
        "        float: The fitness value (lower is better for minimization tasks).\n",
        "    \"\"\"\n",
        "    # Select features based on the binary array\n",
        "    selected_features = X[:, features == 1]\n",
        "\n",
        "    # If no features are selected, return a high fitness value\n",
        "    if selected_features.shape[1] == 0:\n",
        "        return float('inf')\n",
        "\n",
        "    # Perform a simple train-test split (80%-20%)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(selected_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the classifier\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate accuracy\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Return the negative accuracy as fitness (minimization task)\n",
        "    return -accuracy\n"
      ],
      "metadata": {
        "id": "pX9XWjo3W1yf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_swarm(n_particles, n_features, bounds, fitness_function, X, y, classifier):\n",
        "    \"\"\"\n",
        "    Initialize the swarm for PSO.\n",
        "\n",
        "    Args:\n",
        "        n_particles (int): Number of particles.\n",
        "        n_features (int): Number of features.\n",
        "        bounds (tuple): Bounds for the feature mask (binary: 0 or 1).\n",
        "        fitness_function (callable): The fitness function.\n",
        "        X (ndarray): Feature matrix.\n",
        "        y (ndarray): Target array.\n",
        "        classifier: A machine learning model.\n",
        "\n",
        "    Returns:\n",
        "        positions, velocities, pbest_positions, pbest_fitness, gbest_position, gbest_fitness\n",
        "    \"\"\"\n",
        "    lower_bounds, upper_bounds = bounds\n",
        "\n",
        "    # Randomly initialize positions (binary: 0 or 1) and velocities\n",
        "    positions = np.random.randint(lower_bounds, upper_bounds + 1, size=(n_particles, n_features))\n",
        "    velocities = np.random.uniform(-1, 1, (n_particles, n_features))\n",
        "\n",
        "    # Evaluate initial fitness\n",
        "    fitness = np.array([fitness_function(positions[i], X, y, classifier) for i in range(n_particles)])\n",
        "\n",
        "    # Set personal bests (pbest)\n",
        "    pbest_positions = positions.copy()\n",
        "    pbest_fitness = fitness.copy()\n",
        "\n",
        "    # Set global best (gbest)\n",
        "    gbest_index = np.argmin(pbest_fitness)\n",
        "    gbest_position = pbest_positions[gbest_index]\n",
        "    gbest_fitness = pbest_fitness[gbest_index]\n",
        "\n",
        "    return positions, velocities, pbest_positions, pbest_fitness, gbest_position, gbest_fitness\n"
      ],
      "metadata": {
        "id": "5FSJe6s-W-Aw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_best_solution(gbest_position, gbest_fitness, feature_names):\n",
        "    \"\"\"\n",
        "    Return the best solution found by the swarm.\n",
        "\n",
        "    Args:\n",
        "        gbest_position (array): The best feature mask.\n",
        "        gbest_fitness (float): The best fitness value.\n",
        "        feature_names (list): List of feature names.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing selected features and their fitness.\n",
        "    \"\"\"\n",
        "    selected_features = [feature_names[i] for i in range(len(gbest_position)) if gbest_position[i] == 1]\n",
        "    return {\n",
        "        \"Selected Features\": selected_features,\n",
        "        \"Best Fitness\": -gbest_fitness  # Accuracy is the positive value of fitness\n",
        "    }\n"
      ],
      "metadata": {
        "id": "kO45L-wnW_mr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    # Load the dataset\n",
        "    application_record = pd.read_csv(\"path/to/application_record.csv\")\n",
        "    credit_record = pd.read_csv(\"path/to/credit_record.csv\")\n",
        "\n",
        "    # Merge datasets on 'ID'\n",
        "    dataset = pd.merge(application_record, credit_record, on=\"ID\")\n",
        "\n",
        "    # Preprocess dataset\n",
        "    X = dataset.drop(columns=[\"ID\", \"STATUS\"]).values  # Features\n",
        "    y = dataset[\"STATUS\"].map({\"C\": 0, \"X\": 0, \"0\": 1, \"1\": 1, \"2\": 1, \"3\": 1, \"4\": 1, \"5\": 1}).values  # Target\n",
        "\n",
        "    # Parameters (Adjust these based on your dataset)\n",
        "    n_particles = 30  # Number of particles (Try increasing for better exploration)\n",
        "    n_features = X.shape[1]  # Automatically detects the number of features\n",
        "    bounds = (0, 1)  # Binary bounds for feature selection\n",
        "    classifier = DecisionTreeClassifier(random_state=42)  # ML model used for evaluation\n",
        "\n",
        "    # Swarm initialization\n",
        "    positions, velocities, pbest_positions, pbest_fitness, gbest_position, gbest_fitness = initialize_swarm(\n",
        "        n_particles=n_particles,\n",
        "        n_features=n_features,\n",
        "        bounds=bounds,\n",
        "        fitness_function=fitness_function,\n",
        "        X=X,\n",
        "        y=y,\n",
        "        classifier=classifier\n",
        "    )\n",
        "\n",
        "    # Return the best solution\n",
        "    feature_names = dataset.drop(columns=[\"ID\", \"STATUS\"]).columns.tolist()\n",
        "    best_solution = return_best_solution(gbest_position, gbest_fitness, feature_names)\n",
        "\n",
        "    # Output the best solution\n",
        "    print(\"Best Solution Found:\")\n",
        "    print(best_solution)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "OmRlH8AsXDeZ",
        "outputId": "617775be-0cd6-4cf0-e919-b716e32846b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d183407c2ee3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mapplication_record\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path/to/application_record.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcredit_record\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path/to/credit_record.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Genetic Algorithm Implementation"
      ],
      "metadata": {
        "id": "Giuxc_6sZNtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_algorithm_parameters():\n",
        "    \"\"\"Set the parameters for the Genetic Algorithm.\"\"\"\n",
        "    return {\n",
        "        \"pop_size\": 50,\n",
        "        \"num_generations\": 100,\n",
        "        \"crossover_rate\": 0.8,\n",
        "        \"mutation_rate\": 0.01\n",
        "    }"
      ],
      "metadata": {
        "id": "_EglotfOZVFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_parents(population, fitness_values):\n",
        "    \"\"\"Select parents using Tournament Selection.\"\"\"\n",
        "    parents = []\n",
        "    for _ in range(len(population)):\n",
        "        # Tournament selection: Randomly pick 3 and select the best\n",
        "        candidates_idx = np.random.choice(len(population), 3, replace=False)\n",
        "        best_candidate = max(candidates_idx, key=lambda idx: fitness_values[idx])\n",
        "        parents.append(population[best_candidate])\n",
        "    return np.array(parents)\n"
      ],
      "metadata": {
        "id": "a5zT8I3ab95R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crossover(parents, crossover_rate):\n",
        "    \"\"\"Apply single-point crossover.\"\"\"\n",
        "    offspring = []\n",
        "    for i in range(0, len(parents), 2):\n",
        "        parent1, parent2 = parents[i], parents[(i + 1) % len(parents)]\n",
        "        if np.random.rand() < crossover_rate:\n",
        "            point = np.random.randint(1, len(parent1))\n",
        "            child1 = np.concatenate([parent1[:point], parent2[point:]])\n",
        "            child2 = np.concatenate([parent2[:point], parent1[point:]])\n",
        "            offspring.extend([child1, child2])\n",
        "        else:\n",
        "            offspring.extend([parent1, parent2])\n",
        "    return np.array(offspring)\n"
      ],
      "metadata": {
        "id": "vPYPh9wob-eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mutate(offspring, mutation_rate):\n",
        "    \"\"\"Apply bit-flip mutation.\"\"\"\n",
        "    for i in range(len(offspring)):\n",
        "        for j in range(len(offspring[i])):\n",
        "            if np.random.rand() < mutation_rate:\n",
        "                offspring[i][j] = 1 - offspring[i][j]  # Flip bit\n",
        "    return offspring\n"
      ],
      "metadata": {
        "id": "hq0RNObNcFQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def populate_next_generation(offspring, fitness_values):\n",
        "    \"\"\"Replace population with offspring and apply elitism.\"\"\"\n",
        "    elite_idx = np.argmax(fitness_values)\n",
        "    next_generation = offspring\n",
        "    next_generation[0] = offspring[elite_idx]  # Ensure elite survives\n",
        "    return next_generation"
      ],
      "metadata": {
        "id": "psBjdg6fcF4h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}