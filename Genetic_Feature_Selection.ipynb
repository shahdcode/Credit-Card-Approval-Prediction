{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahdcode/Credit-Card-Approval-Prediction/blob/main/Genetic_Feature_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qWoSbYQgDYmZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Particle Swarm Optimization (PSO)"
      ],
      "metadata": {
        "id": "EGCFmGBPU5Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness_function(features, X, y, classifier):\n",
        "    \"\"\"\n",
        "    Evaluate the fitness of a particle.\n",
        "\n",
        "    Args:\n",
        "        features (array): Binary array representing selected features.\n",
        "        X (ndarray): Feature matrix.\n",
        "        y (ndarray): Target array.\n",
        "        classifier: A machine learning model (e.g., DecisionTreeClassifier).\n",
        "\n",
        "    Returns:\n",
        "        float: The fitness value (lower is better for minimization tasks).\n",
        "    \"\"\"\n",
        "    # Select features based on the binary array\n",
        "    selected_features = X[:, features == 1]\n",
        "\n",
        "    # If no features are selected, return a high fitness value\n",
        "    if selected_features.shape[1] == 0:\n",
        "        return float('inf')\n",
        "\n",
        "    # Perform a simple train-test split (80%-20%)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(selected_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the classifier\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate accuracy\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Return the negative accuracy as fitness (minimization task)\n",
        "    return -accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pX9XWjo3W1yf"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_swarm(n_particles, n_features, bounds, fitness_function, X, y, classifier):\n",
        "    \"\"\"\n",
        "    Initialize the swarm for PSO.\n",
        "\n",
        "    Args:\n",
        "        n_particles (int): Number of particles.\n",
        "        n_features (int): Number of features.\n",
        "        bounds (tuple): Bounds for the feature mask (binary: 0 or 1).\n",
        "        fitness_function (callable): The fitness function.\n",
        "        X (ndarray): Feature matrix.\n",
        "        y (ndarray): Target array.\n",
        "        classifier: A machine learning model.\n",
        "\n",
        "    Returns:\n",
        "        positions, velocities, pbest_positions, pbest_fitness, gbest_position, gbest_fitness\n",
        "    \"\"\"\n",
        "    lower_bounds, upper_bounds = bounds\n",
        "\n",
        "    # Randomly initialize positions (binary: 0 or 1) and velocities\n",
        "    positions = np.random.randint(lower_bounds, upper_bounds + 1, size=(n_particles, n_features))\n",
        "    velocities = np.random.uniform(-1, 1, (n_particles, n_features))\n",
        "\n",
        "    # Evaluate initial fitness\n",
        "    fitness = np.array([fitness_function(positions[i], X, y, classifier) for i in range(n_particles)])\n",
        "\n",
        "    # Set personal bests (pbest)\n",
        "    pbest_positions = positions.copy()\n",
        "    pbest_fitness = fitness.copy()\n",
        "\n",
        "    # Set global best (gbest)\n",
        "    gbest_index = np.argmin(pbest_fitness)\n",
        "    gbest_position = pbest_positions[gbest_index]\n",
        "    gbest_fitness = pbest_fitness[gbest_index]\n",
        "\n",
        "    return positions, velocities, pbest_positions, pbest_fitness, gbest_position, gbest_fitness\n"
      ],
      "metadata": {
        "id": "5FSJe6s-W-Aw"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_best_solution(gbest_position, gbest_fitness, feature_names):\n",
        "    \"\"\"\n",
        "    Return the best solution found by the swarm.\n",
        "\n",
        "    Args:\n",
        "        gbest_position (array): The best feature mask.\n",
        "        gbest_fitness (float): The best fitness value.\n",
        "        feature_names (list): List of feature names.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing selected features and their fitness.\n",
        "    \"\"\"\n",
        "    selected_features = [feature_names[i] for i in range(len(gbest_position)) if gbest_position[i] == 1]\n",
        "    return {\n",
        "        \"Selected Features\": selected_features,\n",
        "        \"Best Fitness\": -gbest_fitness  # Accuracy is the positive value of fitness\n",
        "    }\n"
      ],
      "metadata": {
        "id": "kO45L-wnW_mr"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shahd\n",
        "def update_swarm(positions, velocities, fitness_function, pbest_positions, pbest_fitness, gbest_position, w, c1, c2, bounds, X, y, classifier):\n",
        "    lower_bounds, upper_bounds = bounds\n",
        "    n_particles, dimensions = positions.shape\n",
        "\n",
        "    # Temporarily cast positions to float64 for update step\n",
        "    positions = positions.astype(np.float64)\n",
        "\n",
        "    for i in range(n_particles):\n",
        "        # Update velocity\n",
        "        inertia = w * velocities[i]\n",
        "        cognitive = c1 * np.random.random() * (pbest_positions[i] - positions[i])\n",
        "        social = c2 * np.random.random() * (gbest_position - positions[i])\n",
        "        velocities[i] = inertia + cognitive + social\n",
        "\n",
        "        # Update position\n",
        "        positions[i] += velocities[i]\n",
        "\n",
        "        # Ensure positions stay within bounds (binary: 0 or 1)\n",
        "        positions[i] = np.clip(positions[i], lower_bounds, upper_bounds)\n",
        "\n",
        "    # After update, cast positions back to int64 for binary (0, 1)\n",
        "    positions = np.round(positions).astype(np.int64)\n",
        "\n",
        "    # Evaluate fitness\n",
        "    fitness = np.array([fitness_function(positions[i], X, y, classifier) for i in range(n_particles)])\n",
        "\n",
        "    # Update pbest\n",
        "    for i in range(n_particles):\n",
        "        if fitness[i] < pbest_fitness[i]:\n",
        "            pbest_fitness[i] = fitness[i]\n",
        "            pbest_positions[i] = positions[i]\n",
        "\n",
        "    # Update gbest\n",
        "    gbest_index = np.argmin(fitness)\n",
        "    if fitness[gbest_index] < np.min(pbest_fitness):\n",
        "        gbest_position = positions[gbest_index]\n",
        "\n",
        "    return positions, velocities, pbest_positions, pbest_fitness, gbest_position\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AOLz7TzpI5vg"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Genetic Algorithm Implementation"
      ],
      "metadata": {
        "id": "Giuxc_6sZNtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1 - Shahd\n",
        "def encode_solution_space(num_features):\n",
        "    \"\"\"Creates binary encoding for feature selection.\"\"\"\n",
        "    return np.random.choice([0, 1], size=num_features)\n"
      ],
      "metadata": {
        "id": "iGAZQYP0Go55"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2 - Habiba\n",
        "def set_algorithm_parameters():\n",
        "    \"\"\"Set the parameters for the Genetic Algorithm.\"\"\"\n",
        "    return {\n",
        "        \"pop_size\": 50,\n",
        "        \"num_generations\": 100,\n",
        "        \"crossover_rate\": 0.8,\n",
        "        \"mutation_rate\": 0.01\n",
        "    }"
      ],
      "metadata": {
        "id": "_EglotfOZVFJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3 - Shahd\n",
        "def create_initial_population(pop_size, num_features):\n",
        "    \"\"\"Generates the initial population of chromosomes.\"\"\"\n",
        "    return [encode_solution_space(num_features) for _ in range(pop_size)]"
      ],
      "metadata": {
        "id": "KNJ9TMGfGwob"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4 - Shahd\n",
        "def measure_fitness(population, X_train, y_train, X_val, y_val, best_k=5):\n",
        "    \"\"\"Evaluates the fitness of each chromosome (feature selection) in the population.\"\"\"\n",
        "    fitness_scores = []\n",
        "    for chromosome in population:\n",
        "        selected_features = [i for i, bit in enumerate(chromosome) if bit == 1]\n",
        "        if not selected_features:\n",
        "            fitness_scores.append(0)\n",
        "            continue\n",
        "        X_train_selected = X_train[:, selected_features]\n",
        "        X_val_selected = X_val[:, selected_features]\n",
        "\n",
        "        # Train the model with the default value for k (e.g., k=5)\n",
        "        model = KNeighborsClassifier(n_neighbors=best_k)\n",
        "        model.fit(X_train_selected, y_train)\n",
        "        predictions = model.predict(X_val_selected)\n",
        "        fitness_scores.append(accuracy_score(y_val, predictions))\n",
        "    return fitness_scores\n"
      ],
      "metadata": {
        "id": "FAWSwijVG1m8"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5 - Habiba\n",
        "def select_parents(population, fitness_values):\n",
        "    \"\"\"Select parents using Tournament Selection.\"\"\"\n",
        "    parents = []\n",
        "    for _ in range(len(population)):\n",
        "        # Tournament selection: Randomly pick 3 and select the best\n",
        "        candidates_idx = np.random.choice(len(population), 3, replace=False)\n",
        "        best_candidate = max(candidates_idx, key=lambda idx: fitness_values[idx])\n",
        "        parents.append(population[best_candidate])\n",
        "    return np.array(parents)\n"
      ],
      "metadata": {
        "id": "a5zT8I3ab95R"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6 - Habiba\n",
        "def crossover(parents, crossover_rate):\n",
        "    \"\"\"Apply single-point crossover.\"\"\"\n",
        "    offspring = []\n",
        "    for i in range(0, len(parents), 2):\n",
        "        parent1, parent2 = parents[i], parents[(i + 1) % len(parents)]\n",
        "        if np.random.rand() < crossover_rate:\n",
        "            point = np.random.randint(1, len(parent1))\n",
        "            child1 = np.concatenate([parent1[:point], parent2[point:]])\n",
        "            child2 = np.concatenate([parent2[:point], parent1[point:]])\n",
        "            offspring.extend([child1, child2])\n",
        "        else:\n",
        "            offspring.extend([parent1, parent2])\n",
        "    return np.array(offspring)\n"
      ],
      "metadata": {
        "id": "vPYPh9wob-eq"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 7 - Habiba\n",
        "def populate_next_generation(offspring, fitness_values):\n",
        "    \"\"\"Replace population with offspring and apply elitism.\"\"\"\n",
        "    elite_idx = np.argmax(fitness_values)\n",
        "    next_generation = offspring\n",
        "    next_generation[0] = offspring[elite_idx]  # Ensure elite survives\n",
        "    return next_generation"
      ],
      "metadata": {
        "id": "psBjdg6fcF4h"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 8 - Habiba\n",
        "def mutate(offspring, mutation_rate):\n",
        "    \"\"\"Apply bit-flip mutation.\"\"\"\n",
        "    for i in range(len(offspring)):\n",
        "        for j in range(len(offspring[i])):\n",
        "            if np.random.rand() < mutation_rate:\n",
        "                offspring[i][j] = 1 - offspring[i][j]  # Flip bit\n",
        "    return offspring\n"
      ],
      "metadata": {
        "id": "hq0RNObNcFQa"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 9 - Shahd\n",
        "def check_stopping_condition(generation, max_generations, fitness_scores, threshold, no_change_limit, previous_scores):\n",
        "    \"\"\"Checks if the algorithm should stop based on fitness, generations, or stagnation.\"\"\"\n",
        "    if generation >= max_generations or max(fitness_scores) >= threshold:\n",
        "        return True\n",
        "    if len(previous_scores) >= no_change_limit and all(score == previous_scores[0] for score in previous_scores):\n",
        "        return True\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "KxcB3rUmG5PH"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def genetic_algorithm(X_train, y_train, X_val, y_val, num_features):\n",
        "    \"\"\"Runs the genetic algorithm for feature selection.\"\"\"\n",
        "    params = set_algorithm_parameters()\n",
        "    params['no_change_limit'] = 10  # Define stagnation limit\n",
        "    population = create_initial_population(params['pop_size'], num_features)\n",
        "    previous_scores = []\n",
        "\n",
        "    for generation in range(params['num_generations']):\n",
        "        fitness_scores = measure_fitness(population, X_train, y_train, X_val, y_val)\n",
        "\n",
        "        if check_stopping_condition(generation, params['num_generations'], fitness_scores, 0.95, params['no_change_limit'], previous_scores):\n",
        "            break\n",
        "\n",
        "        previous_scores.append(max(fitness_scores))\n",
        "        if len(previous_scores) > params['no_change_limit']:\n",
        "            previous_scores.pop(0)\n",
        "\n",
        "        parents = select_parents(population, fitness_scores)\n",
        "        offspring = crossover(parents, params['crossover_rate'])\n",
        "        offspring = mutate(offspring, params['mutation_rate'])\n",
        "        population = populate_next_generation(offspring, fitness_scores)\n",
        "\n",
        "    best_solution = population[np.argmax(fitness_scores)]\n",
        "    return best_solution, max(fitness_scores)  # Return best solution and fitness score\n"
      ],
      "metadata": {
        "id": "FGKav0l0Huy1"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knn"
      ],
      "metadata": {
        "id": "GrVJKEH8NzO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_optimal_k(X_train, y_train):\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "    param_grid = {'n_neighbors': list(range(1, 31))}\n",
        "    grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search.best_params_['n_neighbors'], grid_search.best_score_\n"
      ],
      "metadata": {
        "id": "XGFx9norODWB"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping 7agat me4 mohema\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/Ai project/Feature_eng.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Drop specific columns\n",
        "df = df.drop(columns=['ID', 'FLAG_MOBIL', 'STATUS'])\n",
        "\n",
        "# Save the updated DataFrame back to CSV\n",
        "df.to_csv('/content/drive/MyDrive/Ai project/Feature_eng_updated.csv', index=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N5ipH8aL4Kmn"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data(X, y, test_size=0.3, val_size=0.5, random_state=42):\n",
        "    \"\"\"\n",
        "    Function to split the dataset into training, validation, and test sets.\n",
        "\n",
        "    Parameters:\n",
        "    - X: Features\n",
        "    - y: Target labels\n",
        "    - test_size: Proportion of data to allocate to the test set\n",
        "    - val_size: Proportion of data to allocate to the validation set (after splitting the test set)\n",
        "    - random_state: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    - X_train, X_val, X_test, y_train, y_val, y_test: The split datasets\n",
        "    \"\"\"\n",
        "    # Step 1: Split into 70% training and 30% temp (which will be further split into validation and test)\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, stratify=y, random_state=random_state)\n",
        "\n",
        "    # Step 2: Split temp into validation and testing\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=val_size, stratify=y_temp, random_state=random_state)\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
      ],
      "metadata": {
        "id": "MOqZKbNa64GT"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# Load the data\n",
        "\n",
        "# Drop unnecessary columns and define features/target\n",
        "X = df.drop(columns=['status_mapped']).values  # Features as numpy array\n",
        "y = df['status_mapped'].values                # Target (label)\n",
        "\n",
        "# Call the split_data function\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y)\n",
        "\n",
        "# Run PSO for feature selection (same as previous code)\n",
        "classifier = KNeighborsClassifier()\n",
        "n_particles = 30\n",
        "n_features = X_train.shape[1]\n",
        "bounds = (0, 1)  # Binary feature selection\n",
        "\n",
        "positions, velocities, pbest_positions, pbest_fitness, gbest_position, gbest_fitness = initialize_swarm(\n",
        "    n_particles, n_features, bounds, fitness_function, X_train, y_train, classifier\n",
        ")\n",
        "\n",
        "# Track the PSO process using tqdm\n",
        "for _ in tqdm(range(100), desc=\"PSO Iterations\"):  # Max iterations\n",
        "    positions, velocities, pbest_positions, pbest_fitness, gbest_position = update_swarm(\n",
        "        positions, velocities, fitness_function, pbest_positions, pbest_fitness, gbest_position,\n",
        "        w=0.5, c1=1.5, c2=1.5, bounds=bounds, X=X_train, y=y_train, classifier=classifier\n",
        "    )\n",
        "\n",
        "pso_result = return_best_solution(gbest_position, gbest_fitness, df.drop(columns=['status_mapped']).columns)\n",
        "selected_features_pso = pso_result[\"Selected Features\"]\n",
        "print(\"PSO Best Features:\", selected_features_pso)\n",
        "print(\"PSO Best Fitness (Accuracy):\", pso_result[\"Best Fitness\"])\n",
        "\n",
        "# Filter training, validation, and test sets by PSO-selected features\n",
        "X_train_selected_pso = X_train[:, gbest_position.astype(bool)]\n",
        "X_val_selected_pso = X_val[:, gbest_position.astype(bool)]\n",
        "X_test_selected_pso = X_test[:, gbest_position.astype(bool)]\n",
        "\n",
        "# Train and evaluate KNN with PSO-selected features\n",
        "best_k, best_score = find_optimal_k(X_train_selected_pso, y_train)\n",
        "print(f\"Optimal k (PSO): {best_k} with cross-validation accuracy: {best_score}\")\n",
        "\n",
        "knn_model_pso = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn_model_pso.fit(X_train_selected_pso, y_train)\n",
        "y_pred_pso = knn_model_pso.predict(X_val_selected_pso)\n",
        "accuracy_pso = accuracy_score(y_val, y_pred_pso)\n",
        "print(f\"Accuracy of KNN with PSO-selected features and k={best_k}: {accuracy_pso}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn5fvsukH2Rj",
        "outputId": "47058f6c-4a19-47ad-e422-ac5827df8c3c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PSO Iterations: 100%|██████████| 100/100 [19:32<00:00, 11.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSO Best Features: ['CODE_GENDER', 'FLAG_OWN_CAR', 'CNT_CHILDREN', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'FLAG_PHONE', 'CNT_FAM_MEMBERS', 'AGE_YEARS']\n",
            "PSO Best Fitness (Accuracy): 0.9491675915649278\n",
            "Optimal k (PSO): 15 with cross-validation accuracy: 0.9502264308652514\n",
            "Accuracy of KNN with PSO-selected features and k=15: 0.9496477414007459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the split_data function to split the dataset\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y)\n",
        "\n",
        "# Run Genetic Algorithm for feature selection (without passing best_k)\n",
        "ga_best_solution, ga_best_fitness = genetic_algorithm(X_train, y_train, X_val, y_val, num_features=X_train.shape[1])\n",
        "ga_selected_features = [df.drop(columns=['status_mapped']).columns[i] for i, bit in enumerate(ga_best_solution) if bit == 1]\n",
        "print(\"GA Best Features:\", ga_selected_features)\n",
        "print(\"GA Best Fitness (Accuracy):\", ga_best_fitness)\n",
        "\n",
        "# Filter training, validation, and test sets by GA-selected features\n",
        "X_train_selected_ga = X_train[:, ga_best_solution.astype(bool)]\n",
        "X_val_selected_ga = X_val[:, ga_best_solution.astype(bool)]\n",
        "X_test_selected_ga = X_test[:, ga_best_solution.astype(bool)]\n",
        "\n",
        "# Find optimal k for KNN after feature selection\n",
        "best_k, best_score = find_optimal_k(X_train_selected_ga, y_train)\n",
        "print(f\"Optimal k (GA): {best_k} with cross-validation accuracy: {best_score}\")\n",
        "\n",
        "# Train and evaluate KNN with GA-selected features\n",
        "knn_model_ga = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn_model_ga.fit(X_train_selected_ga, y_train)\n",
        "y_pred_ga = knn_model_ga.predict(X_val_selected_ga)\n",
        "accuracy_ga = accuracy_score(y_val, y_pred_ga)\n",
        "print(f\"Accuracy of KNN with GA-selected features and k={best_k}: {accuracy_ga}\")\n"
      ],
      "metadata": {
        "id": "jxxGykCM7Ij_",
        "outputId": "7f06bf36-a4c4-4d47-a67d-6b66dd11124d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GA Best Features: ['CODE_GENDER', 'FLAG_OWN_REALTY', 'NAME_HOUSING_TYPE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'YEARS_EMPLOYED']\n",
            "GA Best Fitness (Accuracy): 0.9508910070451719\n",
            "Optimal k (GA): 7 with cross-validation accuracy: 0.9503152112415059\n",
            "Accuracy of KNN with GA-selected features and k=7: 0.9488188976377953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACr8k6skjO6-",
        "outputId": "996ecccf-ac19-4f53-f6ef-f053eaff262b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Ai project/Feature_eng.csv')\n",
        "\n",
        "df = df.drop('STATUS', axis=1)\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns=['status_mapped'])  # Features (all columns except target)\n",
        "y = df['status_mapped']                # Target (label)\n",
        "\n",
        "# Split the data into 70% training and 30% remaining (for validation + testing)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# Split the remaining 30% into 15% validation and 15% testing\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "# Save the splits as CSV files (if needed, combine X and y for each split)\n",
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "val_df = pd.concat([X_val, y_val], axis=1)\n",
        "test_df = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "train_df.to_csv('/content/drive/MyDrive/Ai project/train.csv', index=False)\n",
        "val_df.to_csv('/content/drive/MyDrive/Ai project/validation.csv', index=False)\n",
        "test_df.to_csv('/content/drive/MyDrive/Ai project/test.csv', index=False)\n",
        "\n",
        "print(\"Datasets saved successfully:\")\n",
        "print(f\"Train set: {train_df.shape}\")\n",
        "print(f\"Validation set: {val_df.shape}\")\n",
        "print(f\"Test set: {test_df.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxk8Ilg2kqfT",
        "outputId": "50068801-a115-4290-da47-3b6b9a2d0752"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets saved successfully:\n",
            "Train set: (22522, 19)\n",
            "Validation set: (4826, 19)\n",
            "Test set: (4827, 19)\n"
          ]
        }
      ]
    }
  ]
}